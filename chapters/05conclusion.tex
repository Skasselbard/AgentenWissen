% !TEX root = ../main.tex
\chapter{Auswertung}
Wir haben uns zwei Arten von Agenten etwas genauer angeguckt.
Dabei kann man bereits bei diesem begrenzten Umfang einige Erkenntnisse und gewisse Ansätze feststellen.

Das Wissen eines Agenten einzuschränken, sollte bei Agenten mit eigener Wissensbasis relativ unkompliziert sein. 
Es kann von vornherein Wissen weggelassen oder falsches wissen definiert werden.
Durch Manipulation der Aktualisierung von Wissen kann auch zur Simulationszeit Wissen begrenzt werden.
Außerdem können Zeitabhängige Fakten durch fortlaufen der Zeit obsolet und damit falsch werden.

Komplizierter wird es bei dem Thema der kognitiven Verzerrung.
Es ist selbst schon weitläufig und stark Kontextabhängig.
Um eine genaue Analyse von kognitiver Verzerrung (die einer Modellierung vorausgehen sollte) überhaupt vornehmen zu können, muss aber die Norm, von der die Verzerrung abweicht, sinnvoll definiert werden.

Eine allgemeine Modellierung von kognitiver Verzerrung ist schwer vorstellbar, da es so viele Ausprägungen gibt.
Zusätzlich kann das Modell des Agenten die Umsetzung bestimmter Verzerrungen vereinfachen bzw. erschweren.
Es sollte also vorher klar sein, welche Art von Verzerrung betrachtet werden soll.
Mit der Festlegung der Art kann ein passendes Agentenmodell ausgewählt werden, welches diese Art unterstützt.

Abschließend kann noch die Frage gestellt werden, ob man ein Agentenmodell überhaupt ohne kognitive Verzerrung umsetzen kann.
Zum einen ist die Simulation von menschlichem Verhalten durch Agenten selbst nur eine Abstraktion des tatsächlichen Verhaltens.
Zum anderen besteht beim Modellieren immer die Gefahr, dass Verzerrungen durch den Modellierer eingeführt werden.

Das Integrieren von bestimmter kognitiver Verzerrung ist also eine Aufgabe die sicherlich umsetzbar ist.
Ob das jedoch auch für den Ausschluss von kognitiver Verzerrung gilt, ist mindestens fraglich.